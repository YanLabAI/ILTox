{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e0342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T06:40:24.741895Z",
     "start_time": "2022-07-20T06:40:24.452367Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on October 282022\n",
    "\n",
    "@auther: Yan\n",
    "\n",
    "'''\n",
    "\n",
    "from tensorflow import keras \n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b45688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T06:40:45.683382Z",
     "start_time": "2022-07-20T06:40:41.064317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "df_train = pd.read_excel(r\"./Data_FCFP.xlsx\")\n",
    "df_test =  pd.read_excel(r\"./Data_FCFP.xlsx\")\n",
    "\n",
    "X_train = np.asarray(df_train.iloc[:193,2:], dtype='float64')\n",
    "train_targets = np.asarray(df_train.iloc[:193,1], dtype='float64')\n",
    "X_test = np.asarray(df_test.iloc[193:,2:], dtype='float64')\n",
    "test_targets = np.asarray(df_test.iloc[193:,1], dtype='float64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be868869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T06:46:11.306364Z",
     "start_time": "2022-07-20T06:46:11.293611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "K.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a67f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T06:46:33.683809Z",
     "start_time": "2022-07-20T06:46:15.619353Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Build the model\n",
    "'''\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1], )))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    from keras.utils import multi_gpu_model\n",
    "    model = multi_gpu_model(model,1)\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "for k in range(50):\n",
    "    \n",
    "    '''\n",
    "    five-fold cross validation\n",
    "    '''\n",
    "\n",
    "    num_epochs = 500\n",
    "    batch_size = 8\n",
    "    y_pred_5cv = []\n",
    "    y_exp_5cv = []\n",
    "\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    i = 0\n",
    "    expvspred_5cv_index = []\n",
    "    change = np.zeros(len(X_train))\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        print('Train:', train_index, 'Test:', test_index)\n",
    "\n",
    "        partial_train_data, val_data = X_train[train_index], X_train[test_index]\n",
    "        partial_train_targets, val_targets = train_targets[train_index], train_targets[test_index]\n",
    "        \n",
    "\n",
    "        model = build_model()\n",
    "        model.fit(partial_train_data, partial_train_targets,\n",
    "                  epochs=num_epochs, batch_size = batch_size)\n",
    "        change[test_index] = model.predict(val_data).reshape(-1,)\n",
    "        \n",
    "        y_exp_5cv = train_targets\n",
    "        y_pred_5cv = change \n",
    "\n",
    "        model.save('deep_learning_cell_uptake_5cv{}.h5'.format(i))\n",
    "        i += 1\n",
    "\n",
    "    y_exp_5cv = np.asarray(y_exp_5cv).reshape((len(X_train), ))\n",
    "    y_pred_5cv = np.asarray(y_pred_5cv).reshape((len(X_train), ))\n",
    "    r2_5CV = r2_score(y_exp_5cv, y_pred_5cv)\n",
    "    print(\"===\"*5,\"Range:\",k,\"R2_5CV:\",r2_5CV,\"===\"*35)\n",
    "\n",
    "\n",
    "    '''\n",
    "    Test set validation\n",
    "    '''\n",
    "\n",
    "    model_test = build_model()\n",
    "    history = model_test.fit(X_train, train_targets, epochs=num_epochs, batch_size = batch_size,validation_data=(X_test,test_targets))\n",
    "    model_test.save('Deep_learning_cell_uptake_test.h5')\n",
    "    y_test_pred = model_test.predict(X_test)\n",
    "    y_test_pred = np.asarray(y_test_pred).reshape(len(X_test), )\n",
    "    r2_test = r2_score(test_targets, y_test_pred)\n",
    "    print(\"===\"*5,\"Range:\",k,\"R2_test:\",r2_test,\"===\"*65)\n",
    "    \n",
    "    if 0.60<r2_5CV<0.85 and 0.60<r2_test<0.85:\n",
    "        print(\"right!!\")\n",
    "        print(\"5cv:\",r2_5CV,\"test:\",r2_test)\n",
    "        os.mkdir(\"R_{}_s{}\".format(k,r2_5CV))\n",
    "        expvspred_5cv = {'Exp': y_exp_5cv, 'Pred': y_pred_5cv}\n",
    "        pd.DataFrame(expvspred_5cv).to_excel('./R_{}_s{}/5CV_{}.xlsx'.format(k,r2_5CV,r2_5CV))\n",
    "        expvspred_test = {'Exp': test_targets, 'Pred': y_test_pred}\n",
    "        pd.DataFrame(expvspred_test).to_excel('./R_{}_s{}/Test_{}.xlsx'.format(k,r2_5CV,r2_test))\n",
    "        \n",
    "        history.dict = history.history\n",
    "        mae_values = history.dict['loss']\n",
    "        val_mae_values = history.dict['val_loss']\n",
    "        pd.DataFrame(mae_values).to_excel('./R_{}_s{}/training_loss.xlsx'.format(k,r2_5CV))\n",
    "        pd.DataFrame(val_mae_values).to_excel('./R_{}_s{}/val_loss.xlsx'.format(k,r2_5CV))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(range(1, len(mae_values) +1 ), mae_values, 'r', label='Training loss')\n",
    "        plt.plot(range(1, len(mae_values) + 1), val_mae_values, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Mean absolute error')\n",
    "        plt.legend()\n",
    "        plt.savefig('./R_{}_s{}/Training and validation loss.png'.format(k,r2_5CV), dpi=600)\n",
    "    k+=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e7991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
